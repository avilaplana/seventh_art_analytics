version: "3"

x-spark-image: &spark-image
  image: custom-spark-iceberg:latest
  build:
    context: .
    dockerfile: ./load/docker/Dockerfile

x-spark-env: &spark-env
  AWS_ACCESS_KEY_ID: admin
  AWS_SECRET_ACCESS_KEY: password
  AWS_REGION: eu-west-2
  SPARK_RPC_AUTHENTICATION_ENABLED: "no"
  SPARK_RPC_ENCRYPTION_ENABLED: "no"
  SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
  SPARK_SSL_ENABLED: "no"
  SPARK_USER: spark

x-airflow-image: &airflow-image
  image: custom-airflow:latest
  build:
    context: .
    dockerfile: ./airflow/docker/Dockerfile

x-airflow-env: &airflow-env
  AIRFLOW__CORE__EXECUTOR: LocalExecutor
  AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
  AIRFLOW__CORE__LOAD_EXAMPLES: "false"
  AIRFLOW__WEBSERVER__SECRET_KEY: "b7c51d01e7c447d88a07de15efbf14cd"
  S3_ENDPOINT: http://minio:9000
  ACCESS_KEY: admin
  SECRET_KEY: password
  REGION: eu-west-2
  PROJECTS_DIR: ${PROJECTS_DIR}

services:

###########################################################################
# ---------- Spark Standalone cluster with 1 master and 2 workers ---------
###########################################################################
  spark-master:
    <<: *spark-image
    container_name: spark-master
    environment:
      <<: *spark-env
      SPARK_MODE: master
    depends_on:
      - rest
      - minio
    ports:
      - "8080:8080"
    networks:
      - iceberg_net

  spark-worker-1:
    <<: *spark-image
    container_name: spark-worker-1
    environment:
      <<: *spark-env
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_MEMORY: 2G
      SPARK_WORKER_CORES: 2
    depends_on:
      - spark-master
    networks:
      - iceberg_net

  spark-worker-2:
    <<: *spark-image
    container_name: spark-worker-2
    environment:
      <<: *spark-env
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_MEMORY: 2G
      SPARK_WORKER_CORES: 2
    depends_on:
      - spark-master
    networks:
      - iceberg_net

###########################################################################
# ---------- Spark Thrift Server to allow JDBC/ODBC connections -----------
###########################################################################
  spark-thrift-server:
    <<: *spark-image
    container_name: spark-thrift-server
    depends_on:
      - spark-master
    ports:
      - "4040:4040"
      - "10000:10000"
    command: >
      sh -c "
      sleep 30 &&
      ./sbin/start-thriftserver.sh --master spark://spark-master:7077
      --conf spark.sql.catalog.demo.s3.access-key-id=admin
      --conf spark.sql.catalog.demo.s3.secret-access-key=password
      --conf spark.driver.extraJavaOptions='-Daws.region=eu-west-2'
      --conf spark.executor.extraJavaOptions='-Daws.region=eu-west-2'
      --conf spark.executor.cores=1
      --conf spark.cores.max=1
      --conf spark.executor.memory=1G
      --conf spark.driver.memory=1G"
    networks:
      - iceberg_net
  
###########################################################################
# ---------- Iceberg Rest Server with Postgres as metadata store ---------- 
###########################################################################

  rest:
    image: tabulario/iceberg-rest
    container_name: iceberg-rest
    networks:
      iceberg_net:
    ports:
      - 8181:8181
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=eu-west-2
      - CATALOG_WAREHOUSE=s3://warehouse/
      - CATALOG_IO__IMPL=org.apache.iceberg.aws.s3.S3FileIO
      - CATALOG_S3_ENDPOINT=http://minio:9000
      - CATALOG_URI=jdbc:postgresql://postgres:5432/catalog_metadata
      - CATALOG_JDBC_USER=iceberg
      - CATALOG_JDBC_PASSWORD=iceberg
    depends_on:
      postgres:
        condition: service_healthy

#####################################################
# ---------- Minio (S3-compatible storage) ----------
#####################################################
  minio:
    image: minio/minio
    container_name: minio
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password
      - MINIO_DOMAIN=minio
    networks:
      iceberg_net:
        aliases:
          - warehouse.minio
    ports:
      - 9001:9001
      - 9000:9000
    command: ["server", "/data", "--console-address", ":9001"]
    volumes:
      - minio_data:/data
  mc:
    depends_on:
      - minio
    image: minio/mc
    container_name: mc
    networks:
      iceberg_net:
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=eu-west-2
    entrypoint: >
      /bin/sh -c "
      until (/usr/bin/mc alias set minio http://minio:9000/ admin password) do echo '...waiting...' && sleep 1; done;
      /usr/bin/mc mb minio/warehouse || echo 'Warehouse already exists';
      /usr/bin/mc policy set public minio/warehouse;
      tail -f /dev/null
      "

###############################################################################
# ---------- Database with 2 databases: airflow and catalog_metadata ----------
###############################################################################
  postgres:
    image: postgres:14
    container_name: postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_db_volume:/var/lib/postgresql/data
      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      iceberg_net:
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h localhost -U postgres -p 5432 || exit 1"]
      interval: 5s       # how often to run the check
      timeout: 3s        # fail if check takes longer
      retries: 10        # how many times to retry before unhealthy
      start_period: 10s  # give Postgres some time to boot

#####################################
# ---------- Airflow stack ----------
#####################################
  airflow-webserver:
    <<: *airflow-image
    container_name: airflow-webserver
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      <<: *airflow-env  
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./extract/src:/opt/airflow/extract/src
      - ./load/src:/opt/airflow/load/src
      - /var/run/docker.sock:/var/run/docker.sock
    command: >
      bash -c "airflow db upgrade &&
               airflow users create --username admin --password admin --firstname a --lastname d --role Admin --email admin@example.com || true &&
               airflow webserver"
    ports:
      - "8088:8080"  # Airflow UI
    networks:
      iceberg_net:

  airflow-scheduler:
    <<: *airflow-image
    container_name: airflow-scheduler
    depends_on:
      - airflow-webserver
    environment:
      <<: *airflow-env      
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./extract/src:/opt/airflow/extract/src
      - ./load/src:/opt/airflow/load/src
      - /var/run/docker.sock:/var/run/docker.sock
    command: >
      bash -c "sleep 10 && airflow scheduler"
    networks:
      iceberg_net:

volumes:
  postgres_db_volume:
  minio_data:

networks:
  iceberg_net:
